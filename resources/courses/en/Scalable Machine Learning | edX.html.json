{
    "description": "Machine learning aims to extract knowledge from data, relying on fundamental concepts in computer science, statistics, probability and optimization. Learning algorithms enable a wide range of applications, from everyday tasks such as product recommendations and spam filtering to bleeding edge applications like self-driving cars and personalized medicine. In the age of ‘Big Data,’ with datasets rapidly growing in size and complexity and cloud computing becoming more pervasive, machine learning techniques are fast becoming a core component of large-scale data processing pipelines.\n \nThis course introduces the underlying statistical and algorithmic principles required to develop scalable real-world machine learning pipelines. We present an integrated view of data processing by highlighting the various components of these pipelines, including exploratory data analysis, feature extraction, supervised learning, and model evaluation. You will gain hands-on experience applying these principles using Apache Spark, a cluster computing system well-suited for large-scale machine learning tasks. You will implement scalable algorithms for fundamental statistical models (linear regression, logistic regression, matrix factorization, principal component analysis) while tackling key problems from domains such as online advertising and cognitive neuroscience.\n \nThis self-assessment document provides a short quiz, as well as online resources that review the relevant background material.  The underlying statistical and algorithmic principles required to develop scalable real-world machine learning pipelines\n\tExploratory data analysis, feature extraction, supervised learning, and model evaluation\n\tApplication of these principles using Apache Spark\n\tHow to implement scalable algorithms for fundamental statistical models",
    "instructors": "Ameet Talwalkar",
    "requirements": "Programming background; comfort with mathematical and algorithmic reasoning; familiarity with basic machine learning concepts; exposure to algorithms, probability, linear algebra and calculus; experience with Python (or the ability to learn it quickly). All exercises will use PySpark, but previous experience with Spark or distributed computing is NOT required. ",
    "length": "5 weeks",
    "effort": "5 - 7 hours per week",
    "prices": "Free\n        \n         \n         Verified Certificate option closed",
    "institutions": "UC BerkeleyX",
    "subjects": "Computer Science",
    "language": "English",
    "url": "https:\/\/www.edx.org\/course\/scalable-machine-learning-uc-berkeleyx-cs190-1x",
    "title": "Scalable Machine Learning"
}